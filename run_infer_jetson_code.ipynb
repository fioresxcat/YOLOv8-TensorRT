{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b602f4e5-06c1-4121-bd9a-1b09315b78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict,namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d8cc85-2a3a-4d15-9fbc-6b939c0105be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, scores, nms_thr):\n",
    "    \"\"\"Single class NMS implemented in Numpy.\"\"\"\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= nms_thr)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "def multiclass_nms(boxes, scores, nms_thr, score_thr):\n",
    "    \"\"\"Multiclass NMS implemented in Numpy\"\"\"\n",
    "    final_dets = []\n",
    "    num_classes = scores.shape[1]\n",
    "    for cls_ind in range(num_classes):\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        valid_score_mask = cls_scores > score_thr\n",
    "        if valid_score_mask.sum() == 0:\n",
    "            continue\n",
    "        else:\n",
    "            valid_scores = cls_scores[valid_score_mask]\n",
    "            valid_boxes = boxes[valid_score_mask]\n",
    "            keep = nms(valid_boxes, valid_scores, nms_thr)\n",
    "            if len(keep) > 0:\n",
    "                cls_inds = np.ones((len(keep), 1)) * cls_ind\n",
    "                dets = np.concatenate(\n",
    "                    [valid_boxes[keep], valid_scores[keep, None], cls_inds], 1\n",
    "                )\n",
    "                final_dets.append(dets)\n",
    "    if len(final_dets) == 0:\n",
    "        return None\n",
    "    return np.concatenate(final_dets, 0)\n",
    "\n",
    "\n",
    "def preproc(image, input_size, mean, std, swap=(2, 0, 1)):\n",
    "    if len(image.shape) == 3:\n",
    "        padded_img = np.ones((input_size[0], input_size[1], 3)) * 114.0\n",
    "    else:\n",
    "        padded_img = np.ones(input_size) * 114.0\n",
    "    img = np.array(image)\n",
    "    r = min(input_size[0] / img.shape[0], input_size[1] / img.shape[1])\n",
    "    resized_img = cv2.resize(\n",
    "        img,\n",
    "        (int(img.shape[1] * r), int(img.shape[0] * r)),\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "    ).astype(np.float32)\n",
    "    padded_img[: int(img.shape[0] * r), : int(img.shape[1] * r)] = resized_img\n",
    "    # if use yolox set \n",
    "    # padded_img = padded_img[:, :, ::-1]\n",
    "    # padded_img /= 255.0\n",
    "    padded_img = padded_img[:, :, ::-1]\n",
    "    padded_img /= 255.0\n",
    "    if mean is not None:\n",
    "        padded_img -= mean\n",
    "    if std is not None:\n",
    "        padded_img /= std\n",
    "    padded_img = padded_img.transpose(swap)\n",
    "    padded_img = np.ascontiguousarray(padded_img, dtype=np.float32)\n",
    "    return padded_img, r\n",
    "\n",
    "def postprocess(predictions, ratio):\n",
    "    boxes = predictions[:, :4]\n",
    "    scores = predictions[:, 4:5] * predictions[:, 5:]\n",
    "    boxes_xyxy = np.ones_like(boxes)\n",
    "    boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2.\n",
    "    boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2.\n",
    "    boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2.\n",
    "    boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2.\n",
    "    boxes_xyxy /= ratio\n",
    "    dets = multiclass_nms(boxes_xyxy, scores, nms_thr=0.45, score_thr=0.25)\n",
    "    return dets\n",
    "\n",
    "\n",
    "_COLORS = np.array(\n",
    "    [\n",
    "        0.000, 0.447, 0.741,\n",
    "        0.850, 0.325, 0.098,\n",
    "        0.929, 0.694, 0.125,\n",
    "        0.494, 0.184, 0.556,\n",
    "    ]\n",
    ").astype(np.float32).reshape(-1, 3)\n",
    "_COLORS = np.array([0.000, 0.447, 0.741]*80).astype(np.float32).reshape(-1, 3)\n",
    "\n",
    "names = ['motorcycle', 'car', 'bus', 'truck']\n",
    "names = [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]\n",
    "\n",
    "def vis(img, boxes, scores, cls_ids, conf=0.5, class_names=None):\n",
    "    for i in range(len(boxes)):\n",
    "        box = boxes[i]\n",
    "        cls_id = int(cls_ids[i])\n",
    "        score = scores[i]\n",
    "        if score < conf:\n",
    "            continue\n",
    "        x0 = int(box[0])\n",
    "        y0 = int(box[1])\n",
    "        x1 = int(box[2])\n",
    "        y1 = int(box[3])\n",
    "\n",
    "        color = (_COLORS[cls_id] * 255).astype(np.uint8).tolist()\n",
    "        text = '{}:{:.1f}%'.format(class_names[cls_id], score * 100)\n",
    "        txt_color = (0, 0, 0) if np.mean(_COLORS[cls_id]) > 0.5 else (255, 255, 255)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        txt_size = cv2.getTextSize(text, font, 0.4, 1)[0]\n",
    "        cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n",
    "\n",
    "        txt_bk_color = (_COLORS[cls_id] * 255 * 0.7).astype(np.uint8).tolist()\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (x0, y0 + 1),\n",
    "            (x0 + txt_size[0] + 1, y0 + int(1.5 * txt_size[1])),\n",
    "            txt_bk_color,\n",
    "            -1\n",
    "        )\n",
    "        cv2.putText(img, text, (x0, y0 + txt_size[1]), font, 0.4, txt_color, thickness=1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b875231c-5ba5-4579-9a08-02208fdf718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'yolov8n-face1.engine'\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8302ec09-071d-4e05-a97d-f0c4fef9f616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/22/2024-13:48:11] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "[08/22/2024-13:48:11] [TRT] [I] Loaded engine size: 7 MiB\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tensorrt_bindings.tensorrt.ICudaEngine' object has no attribute 'num_bindings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m runtime\u001b[38;5;241m.\u001b[39mdeserialize_cuda_engine(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m      7\u001b[0m bindings \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_bindings\u001b[49m):\n\u001b[1;32m      9\u001b[0m     name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_binding_name(index)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname: \u001b[39m\u001b[38;5;124m'\u001b[39m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorrt_bindings.tensorrt.ICudaEngine' object has no attribute 'num_bindings'"
     ]
    }
   ],
   "source": [
    "# Infer TensorRT Engine\n",
    "Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
    "logger = trt.Logger(trt.Logger.INFO)\n",
    "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "with open(w, 'rb') as f, trt.Runtime(logger) as runtime:\n",
    "    model = runtime.deserialize_cuda_engine(f.read())\n",
    "bindings = OrderedDict()\n",
    "for index in range(model.num_bindings):\n",
    "    name = model.get_binding_name(index)\n",
    "    print('name: ', name)\n",
    "    dtype = trt.nptype(model.get_binding_dtype(index))\n",
    "    print('dtype: ', dtype)\n",
    "    shape = tuple(model.get_binding_shape(index))\n",
    "    print('shape: ', shape)\n",
    "    data = torch.from_numpy(np.empty(shape, dtype=np.dtype(dtype))).to(device)\n",
    "    bindings[name] = Binding(name, dtype, shape, data, int(data.data_ptr()))\n",
    "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
    "print('binding addrs: ', binding_addrs)\n",
    "context = model.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06c46e-5e93-4d88-ab33-4c665b0d0ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
